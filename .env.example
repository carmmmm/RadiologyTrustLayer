# Hugging Face token — required to download MedGemma (gated model)
# Get yours at https://huggingface.co/settings/tokens
HF_TOKEN=hf_YOUR_TOKEN_HERE

# Model selection
MEDGEMMA_MODEL_ID=google/medgemma-4b-it

# LoRA adapter on HF Hub (optional — leave blank to use base model)
RTL_LORA_ID=

# Set to "true" to skip model loading and use pre-generated mock results
# Useful for UI development / CI without GPU
MEDGEMMA_MOCK=false

# Inference mode: "local" (transformers) | "api" (HF Inference API)
MEDGEMMA_INFERENCE_MODE=local

# Max tokens for generation
MEDGEMMA_MAX_NEW_TOKENS=1024

# Pipeline prompt version
RTL_PROMPT_VERSION=v1

# SQLite database path (overrides default)
RTL_DB_PATH=

# Storage directory for run outputs
RTL_STORAGE_DIR=
